__artifacts_v2__ = {
    "grok_generatedvideos": {
        "name": "Grok - Videos",
        "description": "Parses videos generated by Grok Imagine",
        "author": "Damien Attoe {damien.attoe@spyderforensics.com}",
        "creation_date": "2025-11-14",
        "last_update_date": "2025-11-14",
        "requirements": "none",
        "category": "Grok",
        "notes": "Tested on version 1.0.71 (Nov 11th, 2025)",
        "paths": ('*/ai.x.grok/cache/*/video-cache/*/*exo','*/ai.x.grok/databases/exoplayer_internal.db'),
        "output_types": ["html", "tsv", "lava"],
        "artifact_icon": "video"
    },
        "grok_useraccount": {
        "name": "Grok - User Account",
        "description": "Parses Ornet Browser Usage Information",
        "author": "Damien Attoe {damien.attoe@spyderforensics.com}",
        "creation_date": "2025-11-14",
        "last_update_date": "2025-11-14",
        "requirements": "none",
        "category": "Grok",
        "notes": "Tested on version 1.0.71 (Nov 11th, 2025)",
        "paths": ('*/ai.x.grok/shared_prefs/INTERCOM_DEDUPER_PREFS.xml', '*/ai.x.grok/shared_prefs/INTERCOM_SDK_USER_PREFS.xml'),
        "output_types": ["html", "tsv", "lava"],
        "artifact_icon": "user"
    }    
}

import os
import datetime
import inspect
from pathlib import Path
import sqlite3
import xml.etree.ElementTree as ET
import json

from scripts.ilapfuncs import artifact_processor, is_platform_windows, check_in_media, open_sqlite_db_readonly, get_sqlite_db_records, get_file_path, media_to_html, is_platform_windows, logfunc

@artifact_processor
def grok_generatedvideos(files_found, report_folder, seeker, wrap_text):
    artifact_info = inspect.stack()[0]
    data_list = []

    db_path = None
    meta_tables = []
    index_tables = []

    for source_path in files_found:
        source_path = str(source_path)
        if not source_path.lower().endswith('.db'):
            continue

        try:
            conn = sqlite3.connect(source_path)
            cur = conn.cursor()

            # Metadata tables: ExoPlayerCacheFileMetadata*
            cur.execute(
                "SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'ExoPlayerCacheFileMetadata%'"
            )
            meta_rows = cur.fetchall()

            # Index tables: ExoPlayerCacheIndex*
            cur.execute(
                "SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'ExoPlayerCacheIndex%'"
            )
            index_rows = cur.fetchall()

            conn.close()

            if meta_rows or index_rows:
                db_path = source_path
                meta_tables = [r[0] for r in meta_rows]
                index_tables = [r[0] for r in index_rows]
                break

        except Exception:
            try:
                conn.close()
            except Exception:
                pass
            continue

    exo_meta = {}
    id_to_url = {}

    if db_path:
        try:
            conn = sqlite3.connect(db_path)
            cur = conn.cursor()

            for tbl in meta_tables:
                try:
                    cur.execute(f"SELECT name, length, last_touch_timestamp FROM '{tbl}'")
                    for name, length, last_touch_timestamp in cur.fetchall():
                        exo_meta[name] = (length, last_touch_timestamp)
                except Exception:
                    continue

            for tbl in index_tables:
                try:
                    cur.execute(f"SELECT id, key FROM '{tbl}'")
                    for rec_id, key in cur.fetchall():
                        try:
                            rec_id_int = int(rec_id)
                        except Exception:
                            continue
                        id_to_url[rec_id_int] = key
                except Exception:
                    continue

            conn.close()
        except Exception:
            pass

    exo_files_present = set()
    for f in files_found:
        f = str(f)
        p = Path(f)
        if p.is_file() and p.suffix.lower() == '.exo':
            exo_files_present.add(p.name)

    for file_found in files_found:
        file_found = str(file_found)
        media_path = Path(file_found)

        if not media_path.is_file():
            continue
        if media_path.suffix.lower() != '.exo':
            continue

        filename = media_path.name
        location = str(media_path.parent)

        # Extract cache ID from filename: "4.0.1763060403970.v3.exo" - first part - 4
        file_id = None
        parts = filename.split(".")
        if len(parts) >= 4:
            try:
                file_id = int(parts[0])
            except Exception:
                file_id = None

        # Extract timestamp from filename (3rd part): 1763060403970 (ms) - UTC
        extracted_ts = ""
        if len(parts) >= 4:
            ts_raw = parts[2]
            try:
                ts = int(ts_raw)
                dt = datetime.datetime.utcfromtimestamp(ts / 1000.0)
                extracted_ts = dt.strftime('%Y-%m-%d %H:%M:%S')
            except Exception:
                extracted_ts = ""

        # Lookup DB metadata by name
        length_val = ""
        db_last_touch_utc = ""
        if filename in exo_meta:
            length_raw, last_touch_raw = exo_meta[filename]
            length_val = str(length_raw)

            try:
                ts2 = int(last_touch_raw)
                dt2 = datetime.datetime.utcfromtimestamp(ts2 / 1000.0)
                db_last_touch_utc = dt2.strftime('%Y-%m-%d %H:%M:%S')
            except Exception:
                db_last_touch_utc = ""

        # Lookup original URL by file_id = CacheIndex.id
        original_url = ""
        content_type = ""
        if file_id is not None and file_id in id_to_url:
            original_url = id_to_url[file_id] or ""
            if original_url.startswith("https://assets.grok.com/users/"):
                content_type = "User Generated"
            elif original_url:
                content_type = "Public"

        missing_flag = "Present"

        media_item = check_in_media(
            artifact_info,
            report_folder,
            seeker,
            files_found,
            file_found,
            filename
        )

        if media_item:
            data_list.append((
                extracted_ts,
                db_last_touch_utc,
                content_type,
                original_url,
                filename,
                location,
                missing_flag,
                media_item
            ))

    for name, (length_raw, last_touch_raw) in exo_meta.items():
        if name in exo_files_present:
            continue 

        filename = name
        location = "" 
        extracted_ts = ""

        parts = filename.split(".")
        if len(parts) >= 4:
            ts_raw = parts[2]
            try:
                ts = int(ts_raw)
                dt = datetime.datetime.utcfromtimestamp(ts / 1000.0)
                extracted_ts = dt.strftime('%Y-%m-%d %H:%M:%S')
            except Exception:
                extracted_ts = ""

        db_last_touch_utc = ""
        try:
            ts2 = int(last_touch_raw)
            dt2 = datetime.datetime.utcfromtimestamp(ts2 / 1000.0)
            db_last_touch_utc = dt2.strftime('%Y-%m-%d %H:%M:%S')
        except Exception:
            db_last_touch_utc = ""

        original_url = ""
        content_type = ""
        file_id = None
        if len(parts) >= 1:
            try:
                file_id = int(parts[0])
            except Exception:
                file_id = None

        if file_id is not None and file_id in id_to_url:
            original_url = id_to_url[file_id] or ""
            if original_url.startswith("https://assets.grok.com/users/"):
                content_type = "User Generated"
            elif original_url:
                content_type = "Public"

        missing_flag = "Not Present"
        media_item = "" 

        data_list.append((
            extracted_ts,
            db_last_touch_utc,
            content_type,
            original_url,
            filename,
            location,
            missing_flag,
            media_item
        ))

    data_headers = (
        ('Filename Timestamp', 'datetime'),
        ('Last Viewed in App', 'datetime'),        
        'Content Type',
        'Original URL',
        'File Name',
        'Location',
        'Cache Video',
        ('Video', 'media')
    )

    return data_headers, data_list, source_path

@artifact_processor
def grok_useraccount(files_found, report_folder, seeker, wrap_text):
    import os
    import xml.etree.ElementTree as ET
    import json
    from pathlib import Path

    data_list = []
    source_path = ""

    user_keys = {
        "intercomsdk-session-INTERCOM_SDK_USER_ID",
        "intercomsdk-session-INTERCOM_SDK_EMAIL_ID"
    }

    for fp in files_found:
        source_path = str(fp)

        if not source_path.lower().endswith(".xml"):
            continue
        if not os.path.isfile(source_path):
            continue

        try:
            tree = ET.parse(source_path)
            root = tree.getroot()
        except Exception:
            continue 

        filename = Path(source_path).name
        path = source_path

        cached_json = None
        for elem in root.iter():
            if elem.get("name") == "CachedAttributes":
                cached_json = (elem.text or "").strip()
                break

        if cached_json:
            try:
                data = json.loads(cached_json)
            except Exception:
                data_list.append(("CachedAttributes_raw", cached_json, filename, path))
            else:
                name = ""
                email = ""
                xusername = ""

                if isinstance(data, dict):
                    name = data.get("name", "") or name
                    email = data.get("email", "") or email

                    custom = data.get("custom_attributes", {})
                    if isinstance(custom, dict):
                        name = custom.get("name", name)
                        email = custom.get("email", email)
                        xusername = custom.get("xUsername", xusername)

                if name:
                    data_list.append(("name", str(name), filename, path))
                if email:
                    data_list.append(("email", str(email), filename, path))
                if xusername:
                    data_list.append(("xUsername", str(xusername), filename, path))

        for elem in root.iter():
            key_name = elem.get("name")
            if key_name not in user_keys:
                continue

            value_raw = (elem.text or "").strip()
            if not value_raw:
                value_raw = (elem.get("value", "") or "").strip()

            data_list.append((key_name, value_raw, filename, path))

    data_headers = ("Key", "Value", "File Name", "Path")

    return data_headers, data_list, source_path

